{
  "latency": {
    "total": {
      "avg": 66.332,
      "p95": 115.765,
      "max": 118.384
    },
    "queue": {
      "avg": 47.565,
      "p95": 99.885,
      "max": 105.715
    },
    "inference": {
      "avg": 18.767,
      "p95": 19.997,
      "max": 20.131
    },
    "gpu_inference": {
      "avg": 2.845,
      "p95": 3.107,
      "max": 3.261
    }
  },
  "throughput": {
    "requests_per_second": 0.305,
    "gpu_minutes": 2.134,
    "requests_per_gpu_minute": 21.087,
    "time_span_sec": 147.77,
    "failed_requests": 0,
    "total_completed_requests": 45
  }
}